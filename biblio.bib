@InProceedings{Ref1,
author="Shotton, Jamie
and Winn, John
and Rother, Carsten
and Criminisi, Antonio",
editor="Leonardis, Ale{\v{s}}
and Bischof, Horst
and Pinz, Axel",
title="TextonBoost: Joint Appearance, Shape and Context Modeling for Multi-class Object Recognition and Segmentation",
booktitle="Computer Vision -- ECCV 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--15",
abstract="This paper proposes a new approach to learning a discriminative model of object classes, incorporating appearance, shape and context information efficiently. The learned model is used for automatic visual recognition and semantic segmentation of photographs. Our discriminative model exploits novel features, based on textons, which jointly model shape and texture. Unary classification and feature selection is achieved using shared boosting to give an efficient classifier which can be applied to a large number of classes. Accurate image segmentation is achieved by incorporating these classifiers in a conditional random field. Efficient training of the model on very large datasets is achieved by exploiting both random feature selection and piecewise training methods.",
isbn="978-3-540-33833-8"
}

@article{encoderDecoder,
author = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
year = {2015},
month = {11},
pages = {},
title = {SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation},
volume = {PP},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
doi = {10.1109/TPAMI.2016.2644615}
}

@article{fabaret,
author = {Farabet, C. and Couprie, C. and Najman, L. and LeCun, Y.},
year = {2013},
title = {Learning hierarchical features for scene labeling},
journal = {IEEE PAMI},
}

@article{long,
author = {Long, J. and Shelhammer, E. and Darrell, T.},
title = {Fully convolutional networks for semantic segmentation},
journal = {CVPR}
}

@misc{droneDataset,
author = {Segmentation Drone Dataset},
howpublished={\url{http://dronedataset.icg.tugraz.at}},
note={Accedido el 10-04-2021}
}

@ARTICLE{resnet,
author = {He, K. and Zhang, X. and Ren, S. and Sun, J.},
title = {Deep residual learning for image recognition},
year = 2015,
journal = {arXiv:1512.03385}}

@ARTICLE{xception,
author = { François Chollet },
title = {Xception: Deep Learning with Depthwise Separable Convolutions},
year = 2017,
journal = {arXiv:1610.02357v3}}

@article{imagenet,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}}

@InProceedings{unet,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@misc{vgg,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{coco,
      title={Microsoft COCO: Common Objects in Context}, 
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2015},
      eprint={1405.0312},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{petDataset,
author = {Omkar M Parkhi and Andrea Vedaldi and Adrew Zisserman and C. V. Jawahar},
howpublished = {\url[https://www.robors.ox.ac.uk/~vgg/data/pets/},
note = {Accedido el 16-04-2021}
}
